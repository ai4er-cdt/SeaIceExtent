{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "UQPuC1nNiPr1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: segmentation_models_pytorch in /home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages (0.2.1)\n",
      "Requirement already satisfied: efficientnet-pytorch==0.6.3 in /home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages (from segmentation_models_pytorch) (0.6.3)\n",
      "Requirement already satisfied: timm==0.4.12 in /home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages (from segmentation_models_pytorch) (0.4.12)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages (from segmentation_models_pytorch) (0.11.3)\n",
      "Requirement already satisfied: pretrainedmodels==0.7.4 in /home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages (from segmentation_models_pytorch) (0.7.4)\n",
      "Requirement already satisfied: torch in /home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages (from efficientnet-pytorch==0.6.3->segmentation_models_pytorch) (1.10.2)\n",
      "Requirement already satisfied: tqdm in /home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (4.62.3)\n",
      "Requirement already satisfied: munch in /home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages (from pretrainedmodels==0.7.4->segmentation_models_pytorch) (2.5.0)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (9.0.0)\n",
      "Requirement already satisfied: numpy in /home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages (from torchvision>=0.5.0->segmentation_models_pytorch) (1.21.5)\n",
      "Requirement already satisfied: typing-extensions in /home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages (from torch->efficientnet-pytorch==0.6.3->segmentation_models_pytorch) (4.0.1)\n",
      "Requirement already satisfied: six in /home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages (from munch->pretrainedmodels==0.7.4->segmentation_models_pytorch) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "!pip install segmentation_models_pytorch\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import glob\n",
    "torch.manual_seed(2022)  # Setting random seed so that augmentations can be reproduced.\n",
    "from SeaIce.unet.dataset_preparation import CustomImageDataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RdNhg6NEiZS8"
   },
   "outputs": [],
   "source": [
    "### This class needs to be imported from a separate file.\n",
    "class CustomImageDataset(Dataset):\n",
    "    \"\"\"GTC Code for a dataset class. The class is instantiated with list of filenames within a directory (created using\n",
    "    the list_npy_filenames function). The __getitem__ method pairs up corresponding image-label .npy file pairs. This\n",
    "    dataset can then be input to a dataloader.\"\"\"\n",
    "\n",
    "    def __init__(self, paths, isSingleBand=True):\n",
    "        self.paths = paths\n",
    "        self.isSingleBand = isSingleBand\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = torch.from_numpy(np.vstack(np.load(self.paths[index][0])).astype(float))\n",
    "        if self.isSingleBand:\n",
    "            image = image[None, :]\n",
    "        else:\n",
    "            #image = torch.permute(image, (3, 1, 2, 0))\n",
    "            image = torch.permute(image, (2, 0, 1))\n",
    "        mask_raw = (np.load(self.paths[index][1]))\n",
    "        maskremap100 = np.where(mask_raw == 100, 0, mask_raw)\n",
    "        maskremap200 = np.where(maskremap100 == 200, 1, maskremap100)\n",
    "        mask = torch.from_numpy(np.vstack(maskremap200).astype(float))\n",
    "        mask = mask[None, :]\n",
    "\n",
    "        # assert image.size == mask.size, \\\n",
    "        #    'Image and mask {name} should be the same size, but are {img.size} and {mask.size}'\n",
    "        #image = image.expand(-1, 3, -1, -1)\n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "B-nDJ8cdiVY8"
   },
   "outputs": [],
   "source": [
    "def create_npy_list(image_directory, img_string=\"sar\"):\n",
    "    \"\"\"A function that returns a list of the names of the SAR/MODIS and labelled .npy files in a directory. These lists can\n",
    "    then be used as an argument for the Dataset class instantiation. The function also checks that the specified directory\n",
    "    contains matching sar or MODIS/labelled pairs -- specifically, a label.npy file for each image file.\"\"\"\n",
    "\n",
    "    img_names = sorted(glob.glob(str(image_directory) + '/*_' + img_string + '.npy'))\n",
    "    label_names = sorted(glob.glob(str(image_directory) + '/*_labels.npy'))\n",
    "\n",
    "    # In-depth file-by-file check for matching sar-label pairs in the directory -- assuming  each sar image has a corresponding\n",
    "    # labeled image.\n",
    "    img_label_pairs = []\n",
    "    for image in img_names:\n",
    "        expected_label_name = image.replace(img_string, \"labels\")\n",
    "        if expected_label_name in label_names:\n",
    "            img_label_pairs.append((image, expected_label_name))\n",
    "        else:\n",
    "            raise Exception(f'{img_string} tile name {image} does not have a matching labeled tile.')\n",
    "\n",
    "    return img_label_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "f6T5rik5pdT_"
   },
   "outputs": [],
   "source": [
    "# If running on colab:\n",
    "\"\"\"\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "from pathlib import Path\n",
    "dir_img = Path('/content/drive/Shareddrives/2021-gtc-sea-ice/trainingdata/tiled/')\n",
    "\"\"\"\n",
    "\n",
    "# If running locally:\n",
    "#dir_img = Path('tiled/')\n",
    "dir_img = Path('/mnt/g/Shared drives/2021-gtc-sea-ice/trainingdata/tiled/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CJrK69SpiXwT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /home/mlisaius/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30331a8a3cb544f39be3eaf2771a0250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/83.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inputs\n",
    "\n",
    "imagery = 'sar' # SAR / MODIS\n",
    "val_percent = 0.1\n",
    "batch_size = 10\n",
    "\n",
    "# Model Creation\n",
    "# 1. Create dataset\n",
    "img_list = create_npy_list(dir_img, 'sar')\n",
    "if imagery == 'sar':\n",
    "    single_channel = True\n",
    "    n_channels = 1\n",
    "else:\n",
    "    single_channel = False\n",
    "    n_channels = 3\n",
    "dataset = CustomImageDataset(img_list, single_channel)\n",
    "\n",
    "# 2. Split into train / validation partitions\n",
    "n_val = int(len(dataset) * val_percent)\n",
    "n_train = len(dataset) - n_val\n",
    "train_set, val_set = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "# 3. Create data loaders\n",
    "loader_args = dict(batch_size=batch_size, num_workers=2, pin_memory=True)\n",
    "train_loader = DataLoader(train_set, shuffle=True, **loader_args)\n",
    "val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)\n",
    "\n",
    "# Specify models settings\n",
    "loss = smp.utils.losses.DiceLoss()\n",
    "metrics = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),\n",
    "]\n",
    "# Can also specify number of UNet steps and channel numbers.\n",
    "model = smp.Unet(encoder_name='resnet34', encoder_weights='imagenet', decoder_use_batchnorm=True,\n",
    "                 decoder_attention_type=None, in_channels=n_channels, classes=1, encoder_depth=5)\n",
    "model = model.double()\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    dict(params=model.parameters(), lr=0.0001),\n",
    "])\n",
    "\n",
    "DEVICE = 'cpu'#torch.device('cuda')\n",
    "\n",
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model,\n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    "    optimizer=optimizer,\n",
    "    verbose=True,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    model,\n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    "    verbose=True,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "# train model for 40 epochs\n",
    "\n",
    "max_score = 0\n",
    "n_epochs = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yYp7uUXfpvux"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "train:   0%|                                                                                    | 0/167 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "if __name__ == '__main__':\n",
    "    for i in range(0, n_epochs):\n",
    "\n",
    "        print('\\nEpoch: {}'.format(i))\n",
    "        train_logs = train_epoch.run(train_loader)\n",
    "        valid_logs = valid_epoch.run(val_loader)\n",
    "\n",
    "        # do something (save model, change lr, etc.)\n",
    "        if max_score < valid_logs['iou_score']:\n",
    "            max_score = valid_logs['iou_score']\n",
    "            torch.save(model, './best_model.pth')\n",
    "            print('Model saved!')\n",
    "\n",
    "        if i == n_epochs/2:\n",
    "            optimizer.param_groups[0]['lr'] = 1e-5\n",
    "            print('Decrease decoder learning rate to 1e-5!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pretrained_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
