{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76d284ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'SeaIce'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_461/4127776558.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork_structure\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/madel/Desktop/code/SeaIceExtent/SeaIce/unet/network_structure.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\" Parts of the U-Net model \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mSeaIce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDoubleConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'SeaIce'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from unet.network_structure import UNet\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_img_and_mask(img, mask):\n",
    "    classes = mask.shape[0] if len(mask.shape) > 2 else 1\n",
    "    fig, ax = plt.subplots(1, classes + 1)\n",
    "    ax[0].set_title('Input image')\n",
    "    ax[0].imshow(img)\n",
    "    if classes > 1:\n",
    "        for i in range(classes):\n",
    "            ax[i + 1].set_title(f'Output mask (class {i + 1})')\n",
    "            #ax[i + 1].imshow(mask[:, :, i])\n",
    "            ax[i + 1].imshow(mask[i, :, :])\n",
    "    else:\n",
    "        ax[1].set_title(f'Output mask')\n",
    "        ax[1].imshow(mask)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def predict_img(net,\n",
    "                full_img,\n",
    "                device,\n",
    "                scale_factor=1,\n",
    "                out_threshold=0.5):\n",
    "    net.eval()\n",
    "    img = full_img #torch.from_numpy(BasicDataset.preprocess(full_img, scale_factor, is_mask=False))\n",
    "    img = img.unsqueeze(0)\n",
    "    img = img.to(device=device, dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = net(img)\n",
    "\n",
    "        if net.n_classes > 1:\n",
    "            probs = F.softmax(output, dim=1)[0]\n",
    "        else:\n",
    "            probs = torch.sigmoid(output)[0]\n",
    "\n",
    "        tf = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            #transforms.Resize((full_img.size[1], full_img.size[0])),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "        full_mask = tf(probs.cpu()).squeeze()\n",
    "\n",
    "    if net.n_classes == 1:\n",
    "        return (full_mask > out_threshold).numpy()\n",
    "    else:\n",
    "        return F.one_hot(full_mask.argmax(dim=0), net.n_classes).permute(2, 0, 1).numpy()\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Predict masks from input images')\n",
    "    parser.add_argument('--model', '-m', default='MODEL.pth', metavar='FILE',\n",
    "                        help='Specify the file in which the model is stored')\n",
    "    parser.add_argument('--input', '-i', metavar='INPUT', nargs='+', help='Filenames of input images', required=True)\n",
    "    parser.add_argument('--output', '-o', metavar='INPUT', nargs='+', help='Filenames of output images')\n",
    "    parser.add_argument('--viz', '-v', action='store_true',\n",
    "                        help='Visualize the images as they are processed')\n",
    "    parser.add_argument('--no-save', '-n', action='store_true', help='Do not save the output masks')\n",
    "    parser.add_argument('--mask-threshold', '-t', type=float, default=0.5,\n",
    "                        help='Minimum probability value to consider a mask pixel white')\n",
    "    parser.add_argument('--scale', '-s', type=float, default=0.5,\n",
    "                        help='Scale factor for the input images')\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def get_output_filenames(args):\n",
    "    def _generate_name(fn):\n",
    "        split = os.path.splitext(fn)\n",
    "        return f'{split[0]}_OUT{split[1]}'\n",
    "\n",
    "    return args.output or list(map(_generate_name, args.input))\n",
    "\n",
    "\n",
    "def mask_to_image(mask: np.ndarray):\n",
    "    if mask.ndim == 2:\n",
    "        return Image.fromarray((mask * 255).astype(np.uint8))\n",
    "    elif mask.ndim == 3:\n",
    "        return Image.fromarray((np.argmax(mask, axis=0) * 255 / mask.shape[0]).astype(np.uint8))\n",
    "    \n",
    "\n",
    "def make_predictions(dir_test, dir_out, viz = False, save = False):\n",
    "    img_list = create_npy_list(dir_test)\n",
    "    \n",
    "    net = UNet(n_channels=1, n_classes=2)\n",
    "\n",
    "    checkpoint = str(dir_checkpoint) + \"/checkpoint_epoch1.pth\"\n",
    "    net.load_state_dict(torch.load(checkpoint))\n",
    "    \n",
    "    for i in enumerate(img_list):\n",
    "        filename = i[1][0]\n",
    "        #print(filename)\n",
    "        logging.info(f'\\nPredicting image {filename} ...')\n",
    "        #img = Image.open(filename)\n",
    "        img = torch.from_numpy(np.vstack(np.load(filename)).astype(float))[None,:]\n",
    "\n",
    "        mask = predict_img(net=net,\n",
    "                            full_img=img,\n",
    "                            scale_factor=0.5,\n",
    "                            out_threshold=0.5,\n",
    "                            device=device)\n",
    "\n",
    "        if viz:\n",
    "             logging.info(f'Visualizing results for image {filename}, close to continue...')\n",
    "             #print(img.size())\n",
    "             plot_img_and_mask(img.squeeze(), mask)\n",
    "\n",
    "        if save:\n",
    "             out_filename = str(dir_out) + \"/\" + str(filename[-33:-4]) + \"_prediction.png\"\n",
    "             print(out_filename)\n",
    "             result = mask_to_image(mask)\n",
    "             result.save(out_filename)\n",
    "             logging.info(f'Mask saved to {out_filename}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99d0e2f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_461/499127374.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdir_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/mnt/g/Shared drives/2021-gtc-sea-ice/model/outtiles/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmake_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'make_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "dir_test = Path('/mnt/g/Shared drives/2021-gtc-sea-ice/trainingdata/testing/')\n",
    "dir_out = Path('/mnt/g/Shared drives/2021-gtc-sea-ice/model/outtiles/')\n",
    "\n",
    "make_predictions(dir_test, dir_out, True, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
