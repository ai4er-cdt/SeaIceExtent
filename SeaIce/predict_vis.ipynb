{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27143cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use an existing, trained and tested model to estimate the sea and ice from one image.\n",
    "from SeaIce.unet.shared import *\n",
    "from SeaIce.unet.model_pretrained import smp.Unet\n",
    "from SeaIce.unet.network_structure import UNet\n",
    "\n",
    "\n",
    "def load_model(model_path, unet_type, image_type):\n",
    "    if image_type == \"modis\":\n",
    "        channels = 3\n",
    "    elif image_type == \"sar\":\n",
    "        channels = 1\n",
    "    if unet_type == \"raw\":\n",
    "        model = UNet(n_channels=channels, n_classes=2, bilinear=True)\n",
    "    elif unet_type == \"pretrained\":\n",
    "        model = smp.Unet(encoder_name='resnet34', encoder_weights='imagenet', decoder_use_batchnorm=True,\n",
    "                 decoder_attention_type=None, in_channels=channels, classes=1, encoder_depth=5)\n",
    "        model = model.double()\n",
    "    state = torch.load(model_path)\n",
    "    model.load_state_dict(state)\n",
    "    return(model)\n",
    "#load_model(r\"./best_model.pth\", \"pretrained\", \"sar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66c35bd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'SeaIce'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_461/4127776558.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork_structure\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/madel/Desktop/code/SeaIceExtent/SeaIce/unet/network_structure.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\"\"\" Parts of the U-Net model \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mSeaIce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshared\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDoubleConv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'SeaIce'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from unet.network_structure import UNet\n",
    "from unet.dataset_preparation import create_npy_list\n",
    "\n",
    "def load_model(model_path, unet_type, image_type):\n",
    "    if image_type == \"modis\":\n",
    "        channels = 3\n",
    "    elif image_type == \"sar\":\n",
    "        channels = 1\n",
    "    if unet_type == \"raw\":\n",
    "        model = UNet(n_channels=channels, n_classes=2, bilinear=True)\n",
    "    elif unet_type == \"pretrained\":\n",
    "        model = smp.Unet(encoder_name='resnet34', encoder_weights='imagenet', decoder_use_batchnorm=True,\n",
    "                 decoder_attention_type=None, in_channels=channels, classes=1, encoder_depth=5)\n",
    "        model = model.double()\n",
    "    state = torch.load(model_path)\n",
    "    model.load_state_dict(state)\n",
    "    return(model)\n",
    "\n",
    "def plot_img_and_mask(img, mask):\n",
    "    classes = mask.shape[0] if len(mask.shape) > 2 else 1\n",
    "    fig, ax = plt.subplots(1, classes + 1)\n",
    "    ax[0].set_title('Input image')\n",
    "    ax[0].imshow(img)\n",
    "    if classes > 1:\n",
    "        for i in range(classes):\n",
    "            ax[i + 1].set_title(f'Output mask (class {i + 1})')\n",
    "            #ax[i + 1].imshow(mask[:, :, i])\n",
    "            ax[i + 1].imshow(mask[i, :, :])\n",
    "    else:\n",
    "        ax[1].set_title(f'Output mask')\n",
    "        ax[1].imshow(mask)\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def predict_img(net,\n",
    "                full_img,\n",
    "                device,\n",
    "                scale_factor=1,\n",
    "                out_threshold=0.5):\n",
    "    net.eval()\n",
    "    img = full_img #torch.from_numpy(BasicDataset.preprocess(full_img, scale_factor, is_mask=False))\n",
    "    img = img.unsqueeze(0)\n",
    "    img = img.to(device=device, dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = net(img)\n",
    "\n",
    "        if net.n_classes > 1:\n",
    "            probs = F.softmax(output, dim=1)[0]\n",
    "        else:\n",
    "            probs = torch.sigmoid(output)[0]\n",
    "\n",
    "        tf = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            #transforms.Resize((full_img.size[1], full_img.size[0])),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "        full_mask = tf(probs.cpu()).squeeze()\n",
    "\n",
    "    if net.n_classes == 1:\n",
    "        return (full_mask > out_threshold).numpy()\n",
    "    else:\n",
    "        return F.one_hot(full_mask.argmax(dim=0), net.n_classes).permute(2, 0, 1).numpy()\n",
    "\n",
    "\n",
    "#def get_args():\n",
    "#    parser = argparse.ArgumentParser(description='Predict masks from input images')\n",
    "#    parser.add_argument('--model', '-m', default='MODEL.pth', metavar='FILE',\n",
    "#                        help='Specify the file in which the model is stored')\n",
    "#    parser.add_argument('--input', '-i', metavar='INPUT', nargs='+', help='Filenames of input images', required=True)\n",
    "#    parser.add_argument('--output', '-o', metavar='INPUT', nargs='+', help='Filenames of output images')\n",
    "#    parser.add_argument('--viz', '-v', action='store_true',\n",
    "#                        help='Visualize the images as they are processed')\n",
    "#    parser.add_argument('--no-save', '-n', action='store_true', help='Do not save the output masks')\n",
    "#    parser.add_argument('--mask-threshold', '-t', type=float, default=0.5,\n",
    "#                        help='Minimum probability value to consider a mask pixel white')\n",
    "#    parser.add_argument('--scale', '-s', type=float, default=0.5,\n",
    "#                        help='Scale factor for the input images')\n",
    "#\n",
    "#    return parser.parse_args()\n",
    "\n",
    "\n",
    "#def get_output_filenames(args):\n",
    "#    def _generate_name(fn):\n",
    "#        split = os.path.splitext(fn)\n",
    "#        return f'{split[0]}_OUT{split[1]}'\n",
    "\n",
    "#    return args.output or list(map(_generate_name, args.input))\n",
    "\n",
    "\n",
    "def mask_to_image(mask: np.ndarray):\n",
    "    if mask.ndim == 2:\n",
    "        return Image.fromarray((mask * 255).astype(np.uint8))\n",
    "    elif mask.ndim == 3:\n",
    "        return Image.fromarray((np.argmax(mask, axis=0) * 255 / mask.shape[0]).astype(np.uint8))\n",
    "    \n",
    "\n",
    "def make_predictions(model_path, unet_type, image_type, dir_test, dir_out, viz = False, save = False):\n",
    "    img_list = create_npy_list(dir_test)\n",
    "    \n",
    "    net = load_model(model_path, unet_type, image_type)\n",
    "\n",
    "    for i in enumerate(img_list):\n",
    "        filename = i[1][0]\n",
    "        logging.info(f'\\nPredicting image {filename} ...')\n",
    "        img = torch.from_numpy(np.vstack(np.load(filename)).astype(float))\n",
    "        if image_type == \"sar\":\n",
    "            img = img[None,:]\n",
    "        elif image_type == \"modis\":\n",
    "            img = torch.permute(img, (2, 0, 1))\n",
    "        \n",
    "        mask = predict_img(net=net,\n",
    "                            full_img=img,\n",
    "                            scale_factor=0.5,\n",
    "                            out_threshold=0.5,\n",
    "                            device=device)\n",
    "\n",
    "        if viz:\n",
    "             logging.info(f'Visualizing results for image {filename}, close to continue...')\n",
    "             #print(img.size())\n",
    "             plot_img_and_mask(img.squeeze(), mask)\n",
    "\n",
    "        if save:\n",
    "             out_filename = str(dir_out) + \"/\" + str(filename[-33:-4]) + \"_prediction.png\"\n",
    "             print(out_filename)\n",
    "             result = mask_to_image(mask)\n",
    "             result.save(out_filename)\n",
    "             logging.info(f'Mask saved to {out_filename}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0af68983",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_461/499127374.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdir_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/mnt/g/Shared drives/2021-gtc-sea-ice/model/outtiles/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmake_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'make_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "dir_test = Path('/mnt/g/Shared drives/2021-gtc-sea-ice/trainingdata/testing/')\n",
    "dir_out = Path('/mnt/g/Shared drives/2021-gtc-sea-ice/model/outtiles/')\n",
    "\n",
    "make_predictions(dir_test, dir_out, True, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
