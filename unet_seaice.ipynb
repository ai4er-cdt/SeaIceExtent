{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5df54470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This version of the U-Net is meant to replicate the sea ice\\n    segmentation framework as found in GitHub written in Tensorflow\\n    using PyTorch and the orginal U-Net framework.\\n    \\n    Original sea ice repo: https://github.com/asylve/Sea-Ice/blob/main/Masking-Modelling.ipynb\\n        \\n    Original U-Net described here: https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/\\n    Many of the functions have been copied and slightly modified with comments from https://github.com/milesial/Pytorch-UNet\\n    The new functions are for the Dataset class and for the create_npy_list function. \\n    \\n    The original U-Net file structure was split into multiple module files. For this working draft, \\n    all functions have been incorporated into this single file in seperate cells along with their package dependancies\\n    so that splitting into seperate modules in the future, if desired, will be simple.\\n    \\n    Additionally, this version has been slightly adapted for the single band SAR tile input compared to\\n    the original 3 band optical image (RGB) input of U-NET. \\n    \\n    Compared to the U-Net, the sea ice segmentation framework: \\n        - Does not use BatchNorm \\n        - Uses Dropout functions throughout\\n        - Concatantes the previous layer and current convoluted layer without bespoke padding\\n          and in slightly different order.\\n        - Softmax transformation in out convolutional layer.\\n        - Begins with 32 out channels rather than 64 and scales to 512 rather than >1000\\n    \\n    To adjust, must change: dir_image, dir_checkpoint, n_channels, n_classes and bilinear variables.\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" PLEASE DO NOT DIRECTLY EDIT THIS FILE.\n",
    "\n",
    "    This version of the U-Net is meant to replicate the sea ice\n",
    "    segmentation framework as found in GitHub written in Tensorflow\n",
    "    using PyTorch and the orginal U-Net framework.\n",
    "    \n",
    "    Original sea ice repo: https://github.com/asylve/Sea-Ice/blob/main/Masking-Modelling.ipynb\n",
    "        \n",
    "    Original U-Net described here: https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/\n",
    "    Many of the functions have been copied and slightly modified with comments from https://github.com/milesial/Pytorch-UNet\n",
    "    The new functions are for the Dataset class and for the create_npy_list function. \n",
    "    \n",
    "    The original U-Net file structure was split into multiple module files. For this working draft, \n",
    "    all functions have been incorporated into this single file in seperate cells along with their package dependancies\n",
    "    so that splitting into seperate modules in the future, if desired, will be simple.\n",
    "    \n",
    "    Additionally, this version has been slightly adapted for the single band SAR tile input compared to\n",
    "    the original 3 band optical image (RGB) input of U-NET. \n",
    "    \n",
    "    Compared to the U-Net, the sea ice segmentation framework: \n",
    "        - Does not use BatchNorm \n",
    "        - Uses Dropout functions throughout\n",
    "        - Concatantes the previous layer and current convoluted layer without bespoke padding\n",
    "          and in slightly different order.\n",
    "        - Softmax transformation in out convolutional layer.\n",
    "        - Begins with 32 out channels rather than 64 and scales to 512 rather than >1000\n",
    "    \n",
    "    To adjust, must change: dir_image, dir_checkpoint, n_channels, n_classes and bilinear variables.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30dba784",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Parts of the U-Net model \"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool, dropout then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(p=0.5, inplace=True),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling, single conv, concatination, dropout, then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            #nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.dconv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        self.dropout = nn.Dropout(p=0.5, inplace=True)\n",
    "            \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        x1 = self.conv(x1)\n",
    "        \n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        #print(x1.size(), x2.size(), x.size())\n",
    "        x = self.dropout(x)\n",
    "        return self.dconv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.outconv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
    "            nn.Softmax() #softmax converts the output to a list of probabilities that must sum to 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.outconv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a2b640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Full assembly of the parts to form the complete network \"\"\"\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 32)\n",
    "        self.down1 = Down(32, 64)\n",
    "        self.down2 = Down(64, 128)\n",
    "        self.down3 = Down(128, 256)\n",
    "        self.down4 = Down(256, 512)\n",
    "        self.up1 = Up(512, 256, bilinear)\n",
    "        self.up2 = Up(256, 128, bilinear)\n",
    "        self.up3 = Up(128, 64, bilinear)\n",
    "        self.up4 = Up(64, 32, bilinear)\n",
    "        self.outc = OutConv(32, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aaaab1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" CNN Dataset preparation functions \"\"\"\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset  # For custom data-sets\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "import numpy as np\n",
    "torch.manual_seed(2022)  # Setting random seed so that augmentations can be reproduced.\n",
    "# From https://discuss.pytorch.org/t/beginner-how-do-i-write-a-custom-dataset-that-allows-me-to-return-image-and-its-target-image-not-label-as-a-pair/13988/4\n",
    "# And https://discuss.pytorch.org/t/how-make-customised-dataset-for-semantic-segmentation/30881\n",
    "\n",
    "\n",
    "def create_npy_list(image_directory, img_string=\"sar\"):\n",
    "    \"\"\"A function that returns a list of the names of the SAR/MODIS and labelled .npy files in a directory. These lists can\n",
    "    then be used as an argument for the Dataset class instantiation. The function also checks that the specified directory \n",
    "    contains matching sar or MODIS/labelled pairs -- specifically, a label.npy file for each image file.\"\"\"\n",
    "\n",
    "    img_names = sorted(glob.glob(str(image_directory) + '/*_' + img_string + '.npy'))\n",
    "    label_names = sorted(glob.glob(str(image_directory) + '/*_labels.npy'))\n",
    "\n",
    "    # In-depth file-by-file check for matching sar-label pairs in the directory -- assuming  each sar image has a corresponding\n",
    "    # labeled image.\n",
    "    img_label_pairs = []\n",
    "    for image in img_names:\n",
    "        expected_label_name = image.replace(img_string, \"labels\")\n",
    "        if expected_label_name in label_names:\n",
    "            img_label_pairs.append((image, expected_label_name))\n",
    "        else:\n",
    "            raise Exception(f'{img_string} tile name {image} does not have a matching labeled tile.')\n",
    "            \n",
    "    return img_label_pairs\n",
    "\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    \"\"\"GTC Code for a dataset class. The class is instantiated with list of filenames within a directory (created using\n",
    "    the list_npy_filenames function). The __getitem__ method pairs up corresponding image-label .npy file pairs. This\n",
    "    dataset can then be input to a dataloader.\"\"\"\n",
    "    \n",
    "    def __init__(self, paths, isSingleBand = True):\n",
    "        self.paths = paths\n",
    "        self.isSingleBand = isSingleBand\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = torch.from_numpy(np.vstack(np.load(self.paths[index][0])).astype(float))\n",
    "        if self.isSingleBand:\n",
    "            image = image[None,:]\n",
    "        else:\n",
    "            image = torch.permute(image, (2,0,1))\n",
    "        mask_raw = (np.load(self.paths[index][1]))\n",
    "        maskremap100 = np.where(mask_raw == 100, 0, mask_raw)\n",
    "        maskremap200 = np.where(maskremap100 == 200, 1, maskremap100)\n",
    "        mask = torch.from_numpy(np.vstack(maskremap200).astype(float))\n",
    "        \n",
    "        #assert image.size == mask.size, \\\n",
    "        #    'Image and mask {name} should be the same size, but are {img.size} and {mask.size}'\n",
    "        \n",
    "        return {\n",
    "            'image': image,\n",
    "            'mask': mask\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths) \n",
    "    \n",
    "\n",
    "class CustomImageAugmentDataset(Dataset):\n",
    "    \"\"\"GTC Code for an augmented dataset class. The class is instantiated with a list of filenames within a directory \n",
    "    (created using the list_npy_filenames function). The __getitem__ method pairs up corresponding image-label .npy file\n",
    "    pairs. If specified, augmentations are also applied to the images with a probability. There is a ~25% chance that \n",
    "    no augmentations are applied and a 20% chance of each of the following augmentations: horizontal flip, vertical \n",
    "    flip, 90 degree rotation (anti-clockwise & clockwise), 180 degree rotation, random crop. Multiple augmentations are\n",
    "    applied in sequence. This dataset can then be input to a dataloader.\"\"\"\n",
    "\n",
    "    def __init__(self, paths, augmentation):\n",
    "        self.paths = paths\n",
    "        self.augmentation = augmentation\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = torch.from_numpy(np.vstack(np.load(self.paths[index][0])).astype(float))[None, :]\n",
    "        mask_raw = (np.load(self.paths[index][1]))\n",
    "        maskremap100 = np.where(mask_raw == 100, 100, mask_raw) # 0\n",
    "        maskremap200 = np.where(maskremap100 == 200, 200, maskremap100) # 1\n",
    "        mask = torch.from_numpy(np.vstack(maskremap200).astype(float))\n",
    "\n",
    "        if self.augmentation:\n",
    "            image_pair = self.augment_image(image, mask)\n",
    "        else:\n",
    "            image_pair = {'image': image, 'mask': mask}\n",
    "\n",
    "        return image_pair\n",
    "\n",
    "    @staticmethod\n",
    "    def augment_image(original_image, original_mask):\n",
    "\n",
    "        augmented_image = original_image\n",
    "        augmented_mask = original_mask\n",
    "\n",
    "        aug_probabilities = np.random.choice(a=[0, 1], size=4, p=[0.75, 0.25])\n",
    "\n",
    "        if aug_probabilities[0]: # Horizontal flip\n",
    "            augment_function = transforms.RandomHorizontalFlip(p=1)\n",
    "            augmented_image, augmented_mask = augment_function(augmented_image), augment_function(augmented_mask)\n",
    "\n",
    "        if aug_probabilities[1]: # Vertical flip\n",
    "            augment_function = transforms.RandomVerticalFlip(p=1)\n",
    "            augmented_image, augmented_mask = augment_function(augmented_image), augment_function(augmented_mask)\n",
    "\n",
    "        if  avg_probabilities[2]: # Rotations\n",
    "            rotations = np.random.choice(a=[1, 2, 3], size=1)\n",
    "            augmented_image = torch.rot90(augmented_image, k=rotations, dims=[1, 2])\n",
    "            augmented_mask = torch.rot90(augmented_mask, k=rotations, dims=[0, 1])\n",
    "\n",
    "        if aug_probabilities[3]: # Random crop (and resize)\n",
    "            augment_function = transforms.Compose([transforms.RandomCrop(size=256),\n",
    "                                                   transforms.Resize(512)])\n",
    "            augmented_image, augmented_mask = augment_function(augmented_image), augment_function(augmented_mask)\n",
    "\n",
    "        \"\"\"\n",
    "        if aug_probabilities[6]: # Gaussian blur\n",
    "            augment_function = transforms.GaussianBlur(kernel_size=(7,13), sigma=(0.1, 0.2))\n",
    "            augmented_image, augmented_mask = augment_function(augmented_image), augment_function(augmented_mask)\n",
    "        \"\"\"\n",
    "        return {'image': augmented_image, 'mask': augmented_mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e607a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Dice Loss scoring functions \"\"\"\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def dice_coeff(input: Tensor, target: Tensor, reduce_batch_first: bool = False, epsilon=1e-6):\n",
    "    # Average of Dice coefficient for all batches, or for a single mask\n",
    "    assert input.size() == target.size()\n",
    "    if input.dim() == 2 and reduce_batch_first:\n",
    "        raise ValueError(f'Dice: asked to reduce batch but got tensor without batch dimension (shape {input.shape})')\n",
    "\n",
    "    if input.dim() == 2 or reduce_batch_first:\n",
    "        inter = torch.dot(input.reshape(-1), target.reshape(-1))\n",
    "        sets_sum = torch.sum(input) + torch.sum(target)\n",
    "        if sets_sum.item() == 0:\n",
    "            sets_sum = 2 * inter\n",
    "\n",
    "        return (2 * inter + epsilon) / (sets_sum + epsilon)\n",
    "    else:\n",
    "        # compute and average metric for each batch element\n",
    "        dice = 0\n",
    "        for i in range(input.shape[0]):\n",
    "            dice += dice_coeff(input[i, ...], target[i, ...])\n",
    "        return dice / input.shape[0]\n",
    "\n",
    "\n",
    "def multiclass_dice_coeff(input: Tensor, target: Tensor, reduce_batch_first: bool = False, epsilon=1e-6):\n",
    "    # Average of Dice coefficient for all classes\n",
    "    assert input.size() == target.size()\n",
    "    dice = 0\n",
    "    for channel in range(input.shape[1]):\n",
    "        dice += dice_coeff(input[:, channel, ...], target[:, channel, ...], reduce_batch_first, epsilon)\n",
    "\n",
    "    return dice / input.shape[1]\n",
    "\n",
    "\n",
    "def dice_loss(input: Tensor, target: Tensor, multiclass: bool = False):\n",
    "    # Dice loss (objective to minimize) between 0 and 1\n",
    "    assert input.size() == target.size()\n",
    "    fn = multiclass_dice_coeff if multiclass else dice_coeff\n",
    "    return 1 - fn(input, target, reduce_batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "162a449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Model evaluation functions \"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def evaluate(net, dataloader, device):\n",
    "    net.eval()\n",
    "    num_val_batches = len(dataloader)\n",
    "    dice_score = 0\n",
    "\n",
    "    # iterate over the validation set\n",
    "    for batch in tqdm(dataloader, total=num_val_batches, desc='Validation round', unit='batch', leave=False):\n",
    "        image, mask_true = batch['image'], batch['mask']\n",
    "        # move images and labels to correct device and type\n",
    "        image = image.to(device=device, dtype=torch.float32)\n",
    "        mask_true = mask_true.to(device=device, dtype=torch.long)\n",
    "        mask_true = F.one_hot(mask_true, net.n_classes).permute(0, 3, 1, 2).float()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # predict the mask\n",
    "            mask_pred = net(image)\n",
    "\n",
    "            # convert to one-hot format\n",
    "            if net.n_classes == 1:\n",
    "                mask_pred = (F.sigmoid(mask_pred) > 0.5).float()\n",
    "                # compute the Dice score\n",
    "                dice_score += dice_coeff(mask_pred, mask_true, reduce_batch_first=False)\n",
    "            else:\n",
    "                mask_pred = F.one_hot(mask_pred.argmax(dim=1), net.n_classes).permute(0, 3, 1, 2).float()\n",
    "                # compute the Dice score, ignoring background\n",
    "                dice_score += multiclass_dice_coeff(mask_pred[:, 1:, ...], mask_true[:, 1:, ...], reduce_batch_first=False)\n",
    "\n",
    "           \n",
    "\n",
    "    net.train()\n",
    "\n",
    "    # Fixes a potential division by zero error\n",
    "    if num_val_batches == 0:\n",
    "        return dice_score\n",
    "    return dice_score / num_val_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfefa63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ya6fitj1) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 2374... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 2.60MB of 2.60MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>learning rate</td><td>███▂▂▂▁▁▁</td></tr><tr><td>step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train loss</td><td>▁▁▁▁▇▅▁▁▁▁▁▁▁▂▁▁█▁█▁█▁▁███▁██▁▃█▂▁▁▁▁▁▁▁</td></tr><tr><td>validation Dice</td><td>▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>learning rate</td><td>0.0</td></tr><tr><td>step</td><td>1609</td></tr><tr><td>train loss</td><td>0.8909</td></tr><tr><td>validation Dice</td><td>0.70432</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 27 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">candlelit-romance-7</strong>: <a href=\"https://wandb.ai/mlisaius/U-Net/runs/ya6fitj1\" target=\"_blank\">https://wandb.ai/mlisaius/U-Net/runs/ya6fitj1</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220214_125435-ya6fitj1/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ya6fitj1). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/mlisaius/my-test-project/runs/1lrkk0dw\" target=\"_blank\">mesmerizing-candy-8</a></strong> to <a href=\"https://wandb.ai/mlisaius/my-test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using device cpu\n",
      "INFO: Network:\n",
      "\t1 input channels\n",
      "\t2 output channels (classes)\n",
      "\tBilinear upscaling\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1lrkk0dw) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 12548... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">mesmerizing-candy-8</strong>: <a href=\"https://wandb.ai/mlisaius/my-test-project/runs/1lrkk0dw\" target=\"_blank\">https://wandb.ai/mlisaius/my-test-project/runs/1lrkk0dw</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220214_153857-1lrkk0dw/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1lrkk0dw). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.10 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/mlisaius/U-Net/runs/ebh8j0yo\" target=\"_blank\">expressive-tulip-8</a></strong> to <a href=\"https://wandb.ai/mlisaius/U-Net\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Starting training:\n",
      "        Epochs:          5\n",
      "        Batch size:      1\n",
      "        Learning rate:   1e-05\n",
      "        Training size:   1669\n",
      "        Validation size: 185\n",
      "        Checkpoints:     True\n",
      "        Device:          cpu\n",
      "        Images scaling:  0.5\n",
      "        Mixed Precision: False\n",
      "    \n",
      "Epoch 1/5:   0%|                                                                              | 0/1669 [00:00<?, ?img/s]/home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "/home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n",
      "Epoch 1/5:  10%|████▋                                          | 166/1669 [09:59<1:24:19,  3.37s/img, loss (batch)=1.57]\n",
      "Validation round:   0%|                                                                      | 0/185 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:   1%|▎                                                             | 1/185 [00:01<05:23,  1.76s/batch]\u001b[A\n",
      "Validation round:   1%|▋                                                             | 2/185 [00:02<04:01,  1.32s/batch]\u001b[A\n",
      "Validation round:   2%|█                                                             | 3/185 [00:03<03:34,  1.18s/batch]\u001b[A\n",
      "Validation round:   2%|█▎                                                            | 4/185 [00:04<03:25,  1.13s/batch]\u001b[A\n",
      "Validation round:   3%|█▋                                                            | 5/185 [00:05<03:19,  1.11s/batch]\u001b[A\n",
      "Validation round:   3%|██                                                            | 6/185 [00:06<03:12,  1.08s/batch]\u001b[A\n",
      "Validation round:   4%|██▎                                                           | 7/185 [00:07<03:09,  1.07s/batch]\u001b[A\n",
      "Validation round:   4%|██▋                                                           | 8/185 [00:09<03:08,  1.06s/batch]\u001b[A\n",
      "Validation round:   5%|███                                                           | 9/185 [00:10<03:06,  1.06s/batch]\u001b[A\n",
      "Validation round:   5%|███▎                                                         | 10/185 [00:11<03:01,  1.04s/batch]\u001b[A\n",
      "Validation round:   6%|███▋                                                         | 11/185 [00:12<03:00,  1.03s/batch]\u001b[A\n",
      "Validation round:   6%|███▉                                                         | 12/185 [00:13<03:00,  1.04s/batch]\u001b[A\n",
      "Validation round:   7%|████▎                                                        | 13/185 [00:14<03:01,  1.05s/batch]\u001b[A\n",
      "Validation round:   8%|████▌                                                        | 14/185 [00:15<03:02,  1.07s/batch]\u001b[A\n",
      "Validation round:   8%|████▉                                                        | 15/185 [00:16<03:03,  1.08s/batch]\u001b[A\n",
      "Validation round:   9%|█████▎                                                       | 16/185 [00:17<03:02,  1.08s/batch]\u001b[A\n",
      "Validation round:   9%|█████▌                                                       | 17/185 [00:18<03:02,  1.09s/batch]\u001b[A\n",
      "Validation round:  10%|█████▉                                                       | 18/185 [00:19<03:00,  1.08s/batch]\u001b[A\n",
      "Validation round:  10%|██████▎                                                      | 19/185 [00:20<03:03,  1.10s/batch]\u001b[A\n",
      "Validation round:  11%|██████▌                                                      | 20/185 [00:21<03:02,  1.11s/batch]\u001b[A\n",
      "Validation round:  11%|██████▉                                                      | 21/185 [00:23<03:05,  1.13s/batch]\u001b[A\n",
      "Validation round:  12%|███████▎                                                     | 22/185 [00:24<03:05,  1.14s/batch]\u001b[A\n",
      "Validation round:  12%|███████▌                                                     | 23/185 [00:25<03:12,  1.19s/batch]\u001b[A\n",
      "Validation round:  13%|███████▉                                                     | 24/185 [00:27<03:30,  1.31s/batch]\u001b[A\n",
      "Validation round:  14%|████████▏                                                    | 25/185 [00:28<03:38,  1.36s/batch]\u001b[A\n",
      "Validation round:  14%|████████▌                                                    | 26/185 [00:30<03:38,  1.37s/batch]\u001b[A\n",
      "Validation round:  15%|████████▉                                                    | 27/185 [00:31<03:48,  1.44s/batch]\u001b[A\n",
      "Validation round:  15%|█████████▏                                                   | 28/185 [00:33<03:49,  1.46s/batch]\u001b[A\n",
      "Validation round:  16%|█████████▌                                                   | 29/185 [00:34<03:48,  1.46s/batch]\u001b[A\n",
      "Validation round:  16%|█████████▉                                                   | 30/185 [00:36<03:41,  1.43s/batch]\u001b[A\n",
      "Validation round:  17%|██████████▏                                                  | 31/185 [00:37<03:41,  1.44s/batch]\u001b[A\n",
      "Validation round:  17%|██████████▌                                                  | 32/185 [00:38<03:34,  1.40s/batch]\u001b[A\n",
      "Validation round:  18%|██████████▉                                                  | 33/185 [00:40<03:28,  1.37s/batch]\u001b[A\n",
      "Validation round:  18%|███████████▏                                                 | 34/185 [00:41<03:24,  1.35s/batch]\u001b[A\n",
      "Validation round:  19%|███████████▌                                                 | 35/185 [00:42<03:20,  1.33s/batch]\u001b[A\n",
      "Validation round:  19%|███████████▊                                                 | 36/185 [00:43<03:13,  1.30s/batch]\u001b[A\n",
      "Validation round:  20%|████████████▏                                                | 37/185 [00:45<03:10,  1.29s/batch]\u001b[A\n",
      "Validation round:  21%|████████████▌                                                | 38/185 [00:46<03:07,  1.28s/batch]\u001b[A\n",
      "Validation round:  21%|████████████▊                                                | 39/185 [00:47<03:04,  1.26s/batch]\u001b[A\n",
      "Validation round:  22%|█████████████▏                                               | 40/185 [00:48<03:01,  1.25s/batch]\u001b[A\n",
      "Validation round:  22%|█████████████▌                                               | 41/185 [00:50<03:00,  1.25s/batch]\u001b[A\n",
      "Validation round:  23%|█████████████▊                                               | 42/185 [00:51<02:56,  1.23s/batch]\u001b[A\n",
      "Validation round:  23%|██████████████▏                                              | 43/185 [00:52<02:51,  1.20s/batch]\u001b[A\n",
      "Validation round:  24%|██████████████▌                                              | 44/185 [00:53<02:47,  1.19s/batch]\u001b[A\n",
      "Validation round:  24%|██████████████▊                                              | 45/185 [00:54<02:45,  1.18s/batch]\u001b[A\n",
      "Validation round:  25%|███████████████▏                                             | 46/185 [00:55<02:40,  1.15s/batch]\u001b[A\n",
      "Validation round:  25%|███████████████▍                                             | 47/185 [00:57<02:37,  1.14s/batch]\u001b[A\n",
      "Validation round:  26%|███████████████▊                                             | 48/185 [00:58<02:35,  1.14s/batch]\u001b[A\n",
      "Validation round:  26%|████████████████▏                                            | 49/185 [00:59<02:32,  1.12s/batch]\u001b[A\n",
      "Validation round:  27%|████████████████▍                                            | 50/185 [01:00<02:29,  1.11s/batch]\u001b[A\n",
      "Validation round:  28%|████████████████▊                                            | 51/185 [01:01<02:25,  1.09s/batch]\u001b[A\n",
      "Validation round:  28%|█████████████████▏                                           | 52/185 [01:02<02:24,  1.09s/batch]\u001b[A\n",
      "Validation round:  29%|█████████████████▍                                           | 53/185 [01:03<02:23,  1.08s/batch]\u001b[A\n",
      "Validation round:  29%|█████████████████▊                                           | 54/185 [01:04<02:22,  1.09s/batch]\u001b[A\n",
      "Validation round:  30%|██████████████████▏                                          | 55/185 [01:05<02:21,  1.09s/batch]\u001b[A\n",
      "Validation round:  30%|██████████████████▍                                          | 56/185 [01:06<02:18,  1.07s/batch]\u001b[A\n",
      "Validation round:  31%|██████████████████▊                                          | 57/185 [01:07<02:15,  1.06s/batch]\u001b[A\n",
      "Validation round:  31%|███████████████████                                          | 58/185 [01:08<02:12,  1.04s/batch]\u001b[A\n",
      "Validation round:  32%|███████████████████▍                                         | 59/185 [01:09<02:10,  1.04s/batch]\u001b[A\n",
      "Validation round:  32%|███████████████████▊                                         | 60/185 [01:10<02:08,  1.03s/batch]\u001b[A\n",
      "Validation round:  33%|████████████████████                                         | 61/185 [01:11<02:06,  1.02s/batch]\u001b[A\n",
      "Validation round:  34%|████████████████████▍                                        | 62/185 [01:12<02:05,  1.02s/batch]\u001b[A\n",
      "Validation round:  34%|████████████████████▊                                        | 63/185 [01:13<02:04,  1.02s/batch]\u001b[A\n",
      "Validation round:  35%|█████████████████████                                        | 64/185 [01:14<02:03,  1.02s/batch]\u001b[A\n",
      "Validation round:  35%|█████████████████████▍                                       | 65/185 [01:15<02:02,  1.02s/batch]\u001b[A\n",
      "Validation round:  36%|█████████████████████▊                                       | 66/185 [01:16<02:01,  1.02s/batch]\u001b[A\n",
      "Validation round:  36%|██████████████████████                                       | 67/185 [01:17<01:59,  1.01s/batch]\u001b[A\n",
      "Validation round:  37%|██████████████████████▍                                      | 68/185 [01:18<01:57,  1.01s/batch]\u001b[A\n",
      "Validation round:  37%|██████████████████████▊                                      | 69/185 [01:19<01:57,  1.01s/batch]\u001b[A\n",
      "Validation round:  38%|███████████████████████                                      | 70/185 [01:20<01:57,  1.03s/batch]\u001b[A\n",
      "Validation round:  38%|███████████████████████▍                                     | 71/185 [01:22<01:59,  1.05s/batch]\u001b[A\n",
      "Validation round:  39%|███████████████████████▋                                     | 72/185 [01:23<01:57,  1.04s/batch]\u001b[A\n",
      "Validation round:  39%|████████████████████████                                     | 73/185 [01:24<01:55,  1.03s/batch]\u001b[A\n",
      "Validation round:  40%|████████████████████████▍                                    | 74/185 [01:25<01:53,  1.02s/batch]\u001b[A\n",
      "Validation round:  41%|████████████████████████▋                                    | 75/185 [01:26<01:52,  1.02s/batch]\u001b[A\n",
      "Validation round:  41%|█████████████████████████                                    | 76/185 [01:27<01:51,  1.03s/batch]\u001b[A\n",
      "Validation round:  42%|█████████████████████████▍                                   | 77/185 [01:28<01:51,  1.03s/batch]\u001b[A\n",
      "Validation round:  42%|█████████████████████████▋                                   | 78/185 [01:29<01:51,  1.04s/batch]\u001b[A\n",
      "Validation round:  43%|██████████████████████████                                   | 79/185 [01:30<01:52,  1.07s/batch]\u001b[A\n",
      "Validation round:  43%|██████████████████████████▍                                  | 80/185 [01:31<01:51,  1.06s/batch]\u001b[A\n",
      "Validation round:  44%|██████████████████████████▋                                  | 81/185 [01:32<01:50,  1.07s/batch]\u001b[A\n",
      "Validation round:  44%|███████████████████████████                                  | 82/185 [01:33<01:48,  1.06s/batch]\u001b[A\n",
      "Validation round:  45%|███████████████████████████▎                                 | 83/185 [01:34<01:48,  1.06s/batch]\u001b[A\n",
      "Validation round:  45%|███████████████████████████▋                                 | 84/185 [01:35<01:47,  1.07s/batch]\u001b[A\n",
      "Validation round:  46%|████████████████████████████                                 | 85/185 [01:36<01:48,  1.09s/batch]\u001b[A\n",
      "Validation round:  46%|████████████████████████████▎                                | 86/185 [01:37<01:46,  1.08s/batch]\u001b[A\n",
      "Validation round:  47%|████████████████████████████▋                                | 87/185 [01:38<01:46,  1.09s/batch]\u001b[A\n",
      "Validation round:  48%|█████████████████████████████                                | 88/185 [01:40<01:46,  1.10s/batch]\u001b[A\n",
      "Validation round:  48%|█████████████████████████████▎                               | 89/185 [01:41<01:45,  1.10s/batch]\u001b[A\n",
      "Validation round:  49%|█████████████████████████████▋                               | 90/185 [01:42<01:44,  1.10s/batch]\u001b[A\n",
      "Validation round:  49%|██████████████████████████████                               | 91/185 [01:43<01:44,  1.11s/batch]\u001b[A\n",
      "Validation round:  50%|██████████████████████████████▎                              | 92/185 [01:44<01:44,  1.12s/batch]\u001b[A\n",
      "Validation round:  50%|██████████████████████████████▋                              | 93/185 [01:45<01:43,  1.13s/batch]\u001b[A\n",
      "Validation round:  51%|██████████████████████████████▉                              | 94/185 [01:46<01:43,  1.13s/batch]\u001b[A\n",
      "Validation round:  51%|███████████████████████████████▎                             | 95/185 [01:48<01:43,  1.15s/batch]\u001b[A\n",
      "Validation round:  52%|███████████████████████████████▋                             | 96/185 [01:49<01:44,  1.17s/batch]\u001b[A\n",
      "Validation round:  52%|███████████████████████████████▉                             | 97/185 [01:50<01:43,  1.17s/batch]\u001b[A\n",
      "Validation round:  53%|████████████████████████████████▎                            | 98/185 [01:51<01:43,  1.19s/batch]\u001b[A\n",
      "Validation round:  54%|████████████████████████████████▋                            | 99/185 [01:52<01:43,  1.20s/batch]\u001b[A\n",
      "Validation round:  54%|████████████████████████████████▍                           | 100/185 [01:54<01:42,  1.21s/batch]\u001b[A\n",
      "Validation round:  55%|████████████████████████████████▊                           | 101/185 [01:55<01:41,  1.21s/batch]\u001b[A\n",
      "Validation round:  55%|█████████████████████████████████                           | 102/185 [01:56<01:41,  1.22s/batch]\u001b[A\n",
      "Validation round:  56%|█████████████████████████████████▍                          | 103/185 [01:58<01:45,  1.29s/batch]\u001b[A\n",
      "Validation round:  56%|█████████████████████████████████▋                          | 104/185 [01:59<01:41,  1.26s/batch]\u001b[A\n",
      "Validation round:  57%|██████████████████████████████████                          | 105/185 [02:00<01:36,  1.20s/batch]\u001b[A\n",
      "Validation round:  57%|██████████████████████████████████▍                         | 106/185 [02:01<01:30,  1.14s/batch]\u001b[A\n",
      "Validation round:  58%|██████████████████████████████████▋                         | 107/185 [02:02<01:27,  1.12s/batch]\u001b[A\n",
      "Validation round:  58%|███████████████████████████████████                         | 108/185 [02:03<01:21,  1.06s/batch]\u001b[A\n",
      "Validation round:  59%|███████████████████████████████████▎                        | 109/185 [02:04<01:19,  1.05s/batch]\u001b[A\n",
      "Validation round:  59%|███████████████████████████████████▋                        | 110/185 [02:05<01:19,  1.06s/batch]\u001b[A\n",
      "Validation round:  60%|████████████████████████████████████                        | 111/185 [02:06<01:17,  1.05s/batch]\u001b[A\n",
      "Validation round:  61%|████████████████████████████████████▎                       | 112/185 [02:07<01:15,  1.03s/batch]\u001b[A\n",
      "Validation round:  61%|████████████████████████████████████▋                       | 113/185 [02:08<01:14,  1.04s/batch]\u001b[A\n",
      "Validation round:  62%|████████████████████████████████████▉                       | 114/185 [02:09<01:12,  1.02s/batch]\u001b[A\n",
      "Validation round:  62%|█████████████████████████████████████▎                      | 115/185 [02:10<01:16,  1.10s/batch]\u001b[A\n",
      "Validation round:  63%|█████████████████████████████████████▌                      | 116/185 [02:11<01:16,  1.10s/batch]\u001b[A\n",
      "Validation round:  63%|█████████████████████████████████████▉                      | 117/185 [02:13<01:16,  1.12s/batch]\u001b[A\n",
      "Validation round:  64%|██████████████████████████████████████▎                     | 118/185 [02:14<01:14,  1.11s/batch]\u001b[A\n",
      "Validation round:  64%|██████████████████████████████████████▌                     | 119/185 [02:15<01:13,  1.12s/batch]\u001b[A\n",
      "Validation round:  65%|██████████████████████████████████████▉                     | 120/185 [02:16<01:12,  1.11s/batch]\u001b[A\n",
      "Validation round:  65%|███████████████████████████████████████▏                    | 121/185 [02:17<01:10,  1.11s/batch]\u001b[A\n",
      "Validation round:  66%|███████████████████████████████████████▌                    | 122/185 [02:18<01:05,  1.05s/batch]\u001b[A\n",
      "Validation round:  66%|███████████████████████████████████████▉                    | 123/185 [02:19<01:03,  1.02s/batch]\u001b[A\n",
      "Validation round:  67%|████████████████████████████████████████▏                   | 124/185 [02:20<01:00,  1.00batch/s]\u001b[A\n",
      "Validation round:  68%|████████████████████████████████████████▌                   | 125/185 [02:21<00:57,  1.04batch/s]\u001b[A\n",
      "Validation round:  68%|████████████████████████████████████████▊                   | 126/185 [02:22<00:56,  1.05batch/s]\u001b[A\n",
      "Validation round:  69%|█████████████████████████████████████████▏                  | 127/185 [02:22<00:53,  1.09batch/s]\u001b[A\n",
      "Validation round:  69%|█████████████████████████████████████████▌                  | 128/185 [02:23<00:51,  1.11batch/s]\u001b[A\n",
      "Validation round:  70%|█████████████████████████████████████████▊                  | 129/185 [02:24<00:49,  1.12batch/s]\u001b[A\n",
      "Validation round:  70%|██████████████████████████████████████████▏                 | 130/185 [02:25<00:49,  1.11batch/s]\u001b[A\n",
      "Validation round:  71%|██████████████████████████████████████████▍                 | 131/185 [02:26<00:49,  1.09batch/s]\u001b[A\n",
      "Validation round:  71%|██████████████████████████████████████████▊                 | 132/185 [02:27<00:49,  1.08batch/s]\u001b[A\n",
      "Validation round:  72%|███████████████████████████████████████████▏                | 133/185 [02:28<00:48,  1.07batch/s]\u001b[A\n",
      "Validation round:  72%|███████████████████████████████████████████▍                | 134/185 [02:29<00:48,  1.06batch/s]\u001b[A\n",
      "Validation round:  73%|███████████████████████████████████████████▊                | 135/185 [02:30<00:48,  1.03batch/s]\u001b[A\n",
      "Validation round:  74%|████████████████████████████████████████████                | 136/185 [02:31<00:47,  1.03batch/s]\u001b[A\n",
      "Validation round:  74%|████████████████████████████████████████████▍               | 137/185 [02:32<00:45,  1.05batch/s]\u001b[A\n",
      "Validation round:  75%|████████████████████████████████████████████▊               | 138/185 [02:33<00:43,  1.07batch/s]\u001b[A\n",
      "Validation round:  75%|█████████████████████████████████████████████               | 139/185 [02:34<00:42,  1.08batch/s]\u001b[A\n",
      "Validation round:  76%|█████████████████████████████████████████████▍              | 140/185 [02:35<00:41,  1.07batch/s]\u001b[A\n",
      "Validation round:  76%|█████████████████████████████████████████████▋              | 141/185 [02:35<00:40,  1.07batch/s]\u001b[A\n",
      "Validation round:  77%|██████████████████████████████████████████████              | 142/185 [02:36<00:40,  1.07batch/s]\u001b[A\n",
      "Validation round:  77%|██████████████████████████████████████████████▍             | 143/185 [02:37<00:39,  1.05batch/s]\u001b[A\n",
      "Validation round:  78%|██████████████████████████████████████████████▋             | 144/185 [02:38<00:39,  1.04batch/s]\u001b[A\n",
      "Validation round:  78%|███████████████████████████████████████████████             | 145/185 [02:39<00:38,  1.05batch/s]\u001b[A\n",
      "Validation round:  79%|███████████████████████████████████████████████▎            | 146/185 [02:40<00:36,  1.06batch/s]\u001b[A\n",
      "Validation round:  79%|███████████████████████████████████████████████▋            | 147/185 [02:41<00:35,  1.08batch/s]\u001b[A\n",
      "Validation round:  80%|████████████████████████████████████████████████            | 148/185 [02:42<00:33,  1.09batch/s]\u001b[A\n",
      "Validation round:  81%|████████████████████████████████████████████████▎           | 149/185 [02:43<00:33,  1.08batch/s]\u001b[A\n",
      "Validation round:  81%|████████████████████████████████████████████████▋           | 150/185 [02:44<00:32,  1.07batch/s]\u001b[A\n",
      "Validation round:  82%|████████████████████████████████████████████████▉           | 151/185 [02:45<00:31,  1.07batch/s]\u001b[A\n",
      "Validation round:  82%|█████████████████████████████████████████████████▎          | 152/185 [02:46<00:31,  1.06batch/s]\u001b[A\n",
      "Validation round:  83%|█████████████████████████████████████████████████▌          | 153/185 [02:47<00:30,  1.06batch/s]\u001b[A\n",
      "Validation round:  83%|█████████████████████████████████████████████████▉          | 154/185 [02:48<00:29,  1.07batch/s]\u001b[A\n",
      "Validation round:  84%|██████████████████████████████████████████████████▎         | 155/185 [02:49<00:27,  1.08batch/s]\u001b[A\n",
      "Validation round:  84%|██████████████████████████████████████████████████▌         | 156/185 [02:50<00:27,  1.05batch/s]\u001b[A\n",
      "Validation round:  85%|██████████████████████████████████████████████████▉         | 157/185 [02:50<00:26,  1.06batch/s]\u001b[A\n",
      "Validation round:  85%|███████████████████████████████████████████████████▏        | 158/185 [02:51<00:25,  1.04batch/s]\u001b[A\n",
      "Validation round:  86%|███████████████████████████████████████████████████▌        | 159/185 [02:52<00:24,  1.04batch/s]\u001b[A\n",
      "Validation round:  86%|███████████████████████████████████████████████████▉        | 160/185 [02:53<00:23,  1.05batch/s]\u001b[A\n",
      "Validation round:  87%|████████████████████████████████████████████████████▏       | 161/185 [02:54<00:22,  1.05batch/s]\u001b[A\n",
      "Validation round:  88%|████████████████████████████████████████████████████▌       | 162/185 [02:55<00:21,  1.05batch/s]\u001b[A\n",
      "Validation round:  88%|████████████████████████████████████████████████████▊       | 163/185 [02:56<00:21,  1.03batch/s]\u001b[A\n",
      "Validation round:  89%|█████████████████████████████████████████████████████▏      | 164/185 [02:57<00:20,  1.04batch/s]\u001b[A\n",
      "Validation round:  89%|█████████████████████████████████████████████████████▌      | 165/185 [02:58<00:19,  1.03batch/s]\u001b[A\n",
      "Validation round:  90%|█████████████████████████████████████████████████████▊      | 166/185 [02:59<00:18,  1.03batch/s]\u001b[A\n",
      "Validation round:  90%|██████████████████████████████████████████████████████▏     | 167/185 [03:00<00:17,  1.04batch/s]\u001b[A\n",
      "Validation round:  91%|██████████████████████████████████████████████████████▍     | 168/185 [03:01<00:16,  1.01batch/s]\u001b[A\n",
      "Validation round:  91%|██████████████████████████████████████████████████████▊     | 169/185 [03:02<00:15,  1.01batch/s]\u001b[A\n",
      "Validation round:  92%|███████████████████████████████████████████████████████▏    | 170/185 [03:03<00:14,  1.03batch/s]\u001b[A\n",
      "Validation round:  92%|███████████████████████████████████████████████████████▍    | 171/185 [03:04<00:13,  1.02batch/s]\u001b[A\n",
      "Validation round:  93%|███████████████████████████████████████████████████████▊    | 172/185 [03:05<00:12,  1.00batch/s]\u001b[A\n",
      "Validation round:  94%|████████████████████████████████████████████████████████    | 173/185 [03:06<00:12,  1.01s/batch]\u001b[A\n",
      "Validation round:  94%|████████████████████████████████████████████████████████▍   | 174/185 [03:07<00:11,  1.01s/batch]\u001b[A\n",
      "Validation round:  95%|████████████████████████████████████████████████████████▊   | 175/185 [03:08<00:10,  1.01s/batch]\u001b[A\n",
      "Validation round:  95%|█████████████████████████████████████████████████████████   | 176/185 [03:09<00:09,  1.02s/batch]\u001b[A\n",
      "Validation round:  96%|█████████████████████████████████████████████████████████▍  | 177/185 [03:10<00:08,  1.01s/batch]\u001b[A\n",
      "Validation round:  96%|█████████████████████████████████████████████████████████▋  | 178/185 [03:11<00:07,  1.00s/batch]\u001b[A\n",
      "Validation round:  97%|██████████████████████████████████████████████████████████  | 179/185 [03:12<00:06,  1.00s/batch]\u001b[A\n",
      "Validation round:  97%|██████████████████████████████████████████████████████████▍ | 180/185 [03:13<00:04,  1.01batch/s]\u001b[A\n",
      "Validation round:  98%|██████████████████████████████████████████████████████████▋ | 181/185 [03:14<00:04,  1.00s/batch]\u001b[A\n",
      "Validation round:  98%|███████████████████████████████████████████████████████████ | 182/185 [03:15<00:02,  1.00batch/s]\u001b[A\n",
      "Validation round:  99%|███████████████████████████████████████████████████████████▎| 183/185 [03:16<00:01,  1.02batch/s]\u001b[A\n",
      "Validation round:  99%|███████████████████████████████████████████████████████████▋| 184/185 [03:17<00:00,  1.03batch/s]\u001b[A\n",
      "Validation round: 100%|████████████████████████████████████████████████████████████| 185/185 [03:18<00:00,  1.04batch/s]\u001b[A\n",
      "                                                                                                                        \u001b[AINFO: Validation Dice score: 0.24664418399333954\n",
      "Epoch 1/5:  20%|█████████▌                                      | 332/1669 [22:01<1:12:30,  3.25s/img, loss (batch)=1.1]\n",
      "Validation round:   0%|                                                                      | 0/185 [00:00<?, ?batch/s]\u001b[A\n",
      "Validation round:   1%|▎                                                             | 1/185 [00:01<05:29,  1.79s/batch]\u001b[A\n",
      "Validation round:   1%|▋                                                             | 2/185 [00:02<04:07,  1.35s/batch]\u001b[A\n",
      "Validation round:   2%|█                                                             | 3/185 [00:03<03:41,  1.22s/batch]\u001b[A\n",
      "Validation round:   2%|█▎                                                            | 4/185 [00:05<03:33,  1.18s/batch]\u001b[A\n",
      "Validation round:   3%|█▋                                                            | 5/185 [00:06<03:26,  1.15s/batch]\u001b[A\n",
      "Validation round:   3%|██                                                            | 6/185 [00:07<03:18,  1.11s/batch]\u001b[A\n",
      "Validation round:   4%|██▎                                                           | 7/185 [00:08<03:13,  1.08s/batch]\u001b[A\n",
      "Validation round:   4%|██▋                                                           | 8/185 [00:09<03:15,  1.10s/batch]\u001b[A\n",
      "Validation round:   5%|███                                                           | 9/185 [00:10<03:03,  1.04s/batch]\u001b[A\n",
      "Validation round:   5%|███▎                                                         | 10/185 [00:11<02:53,  1.01batch/s]\u001b[A\n",
      "Validation round:   6%|███▋                                                         | 11/185 [00:12<02:55,  1.01s/batch]\u001b[A\n",
      "Validation round:   6%|███▉                                                         | 12/185 [00:13<02:51,  1.01batch/s]\u001b[A\n",
      "Validation round:   7%|████▎                                                        | 13/185 [00:14<02:50,  1.01batch/s]\u001b[A\n",
      "Validation round:   8%|████▌                                                        | 14/185 [00:15<02:48,  1.01batch/s]\u001b[A\n",
      "Validation round:   8%|████▉                                                        | 15/185 [00:16<02:45,  1.03batch/s]\u001b[A\n",
      "Validation round:   9%|█████▎                                                       | 16/185 [00:16<02:45,  1.02batch/s]\u001b[A\n",
      "Validation round:   9%|█████▌                                                       | 17/185 [00:17<02:41,  1.04batch/s]\u001b[A\n",
      "Validation round:  10%|█████▉                                                       | 18/185 [00:18<02:44,  1.01batch/s]\u001b[A\n",
      "Validation round:  10%|██████▎                                                      | 19/185 [00:19<02:45,  1.00batch/s]\u001b[A\n",
      "Validation round:  11%|██████▌                                                      | 20/185 [00:20<02:39,  1.03batch/s]\u001b[A\n",
      "Validation round:  11%|██████▉                                                      | 21/185 [00:21<02:33,  1.07batch/s]\u001b[A\n",
      "Validation round:  12%|███████▎                                                     | 22/185 [00:22<02:33,  1.06batch/s]\u001b[A\n",
      "Validation round:  12%|███████▌                                                     | 23/185 [00:23<02:31,  1.07batch/s]\u001b[A\n",
      "Validation round:  13%|███████▉                                                     | 24/185 [00:24<02:25,  1.10batch/s]\u001b[A\n",
      "Validation round:  14%|████████▏                                                    | 25/185 [00:25<02:25,  1.10batch/s]\u001b[A\n",
      "Validation round:  14%|████████▌                                                    | 26/185 [00:26<02:19,  1.14batch/s]\u001b[A\n",
      "Validation round:  15%|████████▉                                                    | 27/185 [00:27<02:19,  1.14batch/s]\u001b[A\n",
      "Validation round:  15%|█████████▏                                                   | 28/185 [00:27<02:16,  1.15batch/s]\u001b[A\n",
      "Validation round:  16%|█████████▌                                                   | 29/185 [00:28<02:14,  1.16batch/s]\u001b[A\n",
      "Validation round:  16%|█████████▉                                                   | 30/185 [00:29<02:15,  1.14batch/s]\u001b[A\n",
      "Validation round:  17%|██████████▏                                                  | 31/185 [00:30<02:19,  1.11batch/s]\u001b[A\n",
      "Validation round:  17%|██████████▌                                                  | 32/185 [00:31<02:18,  1.10batch/s]\u001b[A\n",
      "Validation round:  18%|██████████▉                                                  | 33/185 [00:32<02:14,  1.13batch/s]\u001b[A\n",
      "Validation round:  18%|███████████▏                                                 | 34/185 [00:33<02:17,  1.10batch/s]\u001b[A\n",
      "Validation round:  19%|███████████▌                                                 | 35/185 [00:34<02:12,  1.13batch/s]\u001b[A\n",
      "Validation round:  19%|███████████▊                                                 | 36/185 [00:35<02:15,  1.10batch/s]\u001b[A\n",
      "Validation round:  20%|████████████▏                                                | 37/185 [00:36<02:15,  1.10batch/s]\u001b[A\n",
      "Validation round:  21%|████████████▌                                                | 38/185 [00:37<02:18,  1.06batch/s]\u001b[A\n",
      "Validation round:  21%|████████████▊                                                | 39/185 [00:37<02:15,  1.08batch/s]\u001b[A\n",
      "Validation round:  22%|█████████████▏                                               | 40/185 [00:38<02:17,  1.05batch/s]\u001b[A\n",
      "Validation round:  22%|█████████████▌                                               | 41/185 [00:39<02:13,  1.08batch/s]\u001b[A\n",
      "Validation round:  23%|█████████████▊                                               | 42/185 [00:40<02:11,  1.08batch/s]\u001b[A\n",
      "Validation round:  23%|██████████████▏                                              | 43/185 [00:41<02:11,  1.08batch/s]\u001b[A\n",
      "Validation round:  24%|██████████████▌                                              | 44/185 [00:42<02:12,  1.07batch/s]\u001b[A\n",
      "Validation round:  24%|██████████████▊                                              | 45/185 [00:43<02:13,  1.05batch/s]\u001b[A\n",
      "Validation round:  25%|███████████████▏                                             | 46/185 [00:44<02:08,  1.08batch/s]\u001b[A\n",
      "Validation round:  25%|███████████████▍                                             | 47/185 [00:45<02:05,  1.10batch/s]\u001b[A\n",
      "Validation round:  26%|███████████████▊                                             | 48/185 [00:46<02:03,  1.11batch/s]\u001b[A\n",
      "Validation round:  26%|████████████████▏                                            | 49/185 [00:47<02:04,  1.09batch/s]\u001b[A\n",
      "Validation round:  27%|████████████████▍                                            | 50/185 [00:48<02:00,  1.12batch/s]\u001b[A\n",
      "Validation round:  28%|████████████████▊                                            | 51/185 [00:48<02:00,  1.11batch/s]\u001b[A\n",
      "Validation round:  28%|█████████████████▏                                           | 52/185 [00:49<01:56,  1.14batch/s]\u001b[A\n",
      "Validation round:  29%|█████████████████▍                                           | 53/185 [00:50<01:53,  1.16batch/s]\u001b[A\n",
      "Validation round:  29%|█████████████████▊                                           | 54/185 [00:51<01:55,  1.13batch/s]\u001b[A\n",
      "Validation round:  30%|██████████████████▏                                          | 55/185 [00:52<02:00,  1.08batch/s]\u001b[A\n",
      "Validation round:  30%|██████████████████▍                                          | 56/185 [00:53<01:58,  1.09batch/s]\u001b[A\n",
      "Validation round:  31%|██████████████████▊                                          | 57/185 [00:54<01:58,  1.08batch/s]\u001b[A\n",
      "Validation round:  31%|███████████████████                                          | 58/185 [00:55<01:54,  1.11batch/s]\u001b[A\n",
      "Validation round:  32%|███████████████████▍                                         | 59/185 [00:56<02:02,  1.03batch/s]\u001b[A\n",
      "Validation round:  32%|███████████████████▊                                         | 60/185 [00:57<02:01,  1.03batch/s]\u001b[A\n",
      "Validation round:  33%|████████████████████                                         | 61/185 [00:58<02:00,  1.03batch/s]\u001b[A\n",
      "Validation round:  34%|████████████████████▍                                        | 62/185 [00:59<01:59,  1.03batch/s]\u001b[A\n",
      "Validation round:  34%|████████████████████▊                                        | 63/185 [01:00<01:57,  1.04batch/s]\u001b[A\n",
      "Validation round:  35%|█████████████████████                                        | 64/185 [01:01<01:57,  1.03batch/s]\u001b[A\n",
      "Validation round:  35%|█████████████████████▍                                       | 65/185 [01:02<01:55,  1.04batch/s]\u001b[A\n",
      "Validation round:  36%|█████████████████████▊                                       | 66/185 [01:03<01:56,  1.03batch/s]\u001b[A\n",
      "Validation round:  36%|██████████████████████                                       | 67/185 [01:04<01:53,  1.04batch/s]\u001b[A\n",
      "Validation round:  37%|██████████████████████▍                                      | 68/185 [01:05<01:51,  1.05batch/s]\u001b[A\n",
      "Validation round:  37%|██████████████████████▊                                      | 69/185 [01:05<01:48,  1.06batch/s]\u001b[A\n",
      "Validation round:  38%|███████████████████████                                      | 70/185 [01:07<01:51,  1.03batch/s]\u001b[A\n",
      "Validation round:  38%|███████████████████████▍                                     | 71/185 [01:07<01:50,  1.03batch/s]\u001b[A\n",
      "Validation round:  39%|███████████████████████▋                                     | 72/185 [01:09<01:51,  1.01batch/s]\u001b[A\n",
      "Validation round:  39%|████████████████████████                                     | 73/185 [01:09<01:49,  1.02batch/s]\u001b[A\n",
      "Validation round:  40%|████████████████████████▍                                    | 74/185 [01:10<01:46,  1.04batch/s]\u001b[A\n",
      "Validation round:  41%|████████████████████████▋                                    | 75/185 [01:11<01:46,  1.03batch/s]\u001b[A\n",
      "Validation round:  41%|█████████████████████████                                    | 76/185 [01:12<01:46,  1.02batch/s]\u001b[A\n",
      "Validation round:  42%|█████████████████████████▍                                   | 77/185 [01:13<01:47,  1.01batch/s]\u001b[A\n",
      "Validation round:  42%|█████████████████████████▋                                   | 78/185 [01:14<01:46,  1.00batch/s]\u001b[A\n",
      "Validation round:  43%|██████████████████████████                                   | 79/185 [01:15<01:44,  1.01batch/s]\u001b[A\n",
      "Validation round:  43%|██████████████████████████▍                                  | 80/185 [01:16<01:42,  1.03batch/s]\u001b[A\n",
      "Validation round:  44%|██████████████████████████▋                                  | 81/185 [01:17<01:42,  1.01batch/s]\u001b[A\n",
      "Validation round:  44%|███████████████████████████                                  | 82/185 [01:18<01:41,  1.02batch/s]\u001b[A\n",
      "Validation round:  45%|███████████████████████████▎                                 | 83/185 [01:19<01:40,  1.02batch/s]\u001b[A\n",
      "Validation round:  45%|███████████████████████████▋                                 | 84/185 [01:20<01:40,  1.01batch/s]\u001b[A\n",
      "Validation round:  46%|████████████████████████████                                 | 85/185 [01:21<01:38,  1.01batch/s]\u001b[A\n",
      "Validation round:  46%|████████████████████████████▎                                | 86/185 [01:22<01:39,  1.00s/batch]\u001b[A\n",
      "Validation round:  47%|████████████████████████████▋                                | 87/185 [01:23<01:40,  1.03s/batch]\u001b[A\n",
      "Validation round:  48%|█████████████████████████████                                | 88/185 [01:24<01:39,  1.02s/batch]\u001b[A\n",
      "Validation round:  48%|█████████████████████████████▎                               | 89/185 [01:25<01:36,  1.01s/batch]\u001b[A\n",
      "Validation round:  49%|█████████████████████████████▋                               | 90/185 [01:26<01:35,  1.00s/batch]\u001b[A\n",
      "Validation round:  49%|██████████████████████████████                               | 91/185 [01:27<01:32,  1.02batch/s]\u001b[A\n",
      "Validation round:  50%|██████████████████████████████▎                              | 92/185 [01:28<01:28,  1.05batch/s]\u001b[A\n",
      "Validation round:  50%|██████████████████████████████▋                              | 93/185 [01:29<01:26,  1.06batch/s]\u001b[A\n",
      "Validation round:  51%|██████████████████████████████▉                              | 94/185 [01:30<01:24,  1.08batch/s]\u001b[A\n",
      "Validation round:  51%|███████████████████████████████▎                             | 95/185 [01:31<01:21,  1.10batch/s]\u001b[A\n",
      "Validation round:  52%|███████████████████████████████▋                             | 96/185 [01:32<01:22,  1.08batch/s]\u001b[A\n",
      "Validation round:  52%|███████████████████████████████▉                             | 97/185 [01:33<01:21,  1.08batch/s]\u001b[A\n",
      "Validation round:  53%|████████████████████████████████▎                            | 98/185 [01:34<01:19,  1.09batch/s]\u001b[A\n",
      "Validation round:  54%|████████████████████████████████▋                            | 99/185 [01:35<01:18,  1.10batch/s]\u001b[A\n",
      "Validation round:  54%|████████████████████████████████▍                           | 100/185 [01:36<01:19,  1.07batch/s]\u001b[A\n",
      "Validation round:  55%|████████████████████████████████▊                           | 101/185 [01:36<01:17,  1.08batch/s]\u001b[A\n",
      "Validation round:  55%|█████████████████████████████████                           | 102/185 [01:37<01:15,  1.10batch/s]\u001b[A\n",
      "Validation round:  56%|█████████████████████████████████▍                          | 103/185 [01:38<01:14,  1.10batch/s]\u001b[A\n",
      "Validation round:  56%|█████████████████████████████████▋                          | 104/185 [01:39<01:11,  1.14batch/s]\u001b[A\n",
      "Validation round:  57%|██████████████████████████████████                          | 105/185 [01:40<01:11,  1.11batch/s]\u001b[A\n",
      "Validation round:  57%|██████████████████████████████████▍                         | 106/185 [01:41<01:09,  1.13batch/s]\u001b[A\n",
      "Validation round:  58%|██████████████████████████████████▋                         | 107/185 [01:42<01:07,  1.15batch/s]\u001b[A\n",
      "Validation round:  58%|███████████████████████████████████                         | 108/185 [01:43<01:07,  1.14batch/s]\u001b[A\n",
      "Validation round:  59%|███████████████████████████████████▎                        | 109/185 [01:44<01:08,  1.12batch/s]\u001b[A\n",
      "Validation round:  59%|███████████████████████████████████▋                        | 110/185 [01:44<01:08,  1.10batch/s]\u001b[A\n",
      "Validation round:  60%|████████████████████████████████████                        | 111/185 [01:45<01:08,  1.08batch/s]\u001b[A\n",
      "Validation round:  61%|████████████████████████████████████▎                       | 112/185 [01:46<01:08,  1.07batch/s]\u001b[A\n",
      "Validation round:  61%|████████████████████████████████████▋                       | 113/185 [01:47<01:05,  1.09batch/s]\u001b[A\n",
      "Validation round:  62%|████████████████████████████████████▉                       | 114/185 [01:48<01:06,  1.07batch/s]\u001b[A\n",
      "Validation round:  62%|█████████████████████████████████████▎                      | 115/185 [01:49<01:05,  1.07batch/s]\u001b[A\n",
      "Validation round:  63%|█████████████████████████████████████▌                      | 116/185 [01:50<01:05,  1.05batch/s]\u001b[A\n",
      "Validation round:  63%|█████████████████████████████████████▉                      | 117/185 [01:51<01:04,  1.05batch/s]\u001b[A\n",
      "Validation round:  64%|██████████████████████████████████████▎                     | 118/185 [01:52<01:03,  1.05batch/s]\u001b[A\n",
      "Validation round:  64%|██████████████████████████████████████▌                     | 119/185 [01:53<01:02,  1.05batch/s]\u001b[A\n",
      "Validation round:  65%|██████████████████████████████████████▉                     | 120/185 [01:54<01:02,  1.04batch/s]\u001b[A\n",
      "Validation round:  65%|███████████████████████████████████████▏                    | 121/185 [01:55<01:00,  1.05batch/s]\u001b[A\n",
      "Validation round:  66%|███████████████████████████████████████▌                    | 122/185 [01:56<00:58,  1.07batch/s]\u001b[A\n",
      "Validation round:  66%|███████████████████████████████████████▉                    | 123/185 [01:57<00:58,  1.06batch/s]\u001b[A\n",
      "Validation round:  67%|████████████████████████████████████████▏                   | 124/185 [01:58<00:56,  1.08batch/s]\u001b[A\n",
      "Validation round:  68%|████████████████████████████████████████▌                   | 125/185 [01:59<00:55,  1.08batch/s]\u001b[A\n",
      "Validation round:  68%|████████████████████████████████████████▊                   | 126/185 [02:00<00:55,  1.07batch/s]\u001b[A\n",
      "Validation round:  69%|█████████████████████████████████████████▏                  | 127/185 [02:00<00:54,  1.06batch/s]\u001b[A\n",
      "Validation round:  69%|█████████████████████████████████████████▌                  | 128/185 [02:01<00:53,  1.06batch/s]\u001b[A\n",
      "Validation round:  70%|█████████████████████████████████████████▊                  | 129/185 [02:02<00:53,  1.04batch/s]\u001b[A\n",
      "Validation round:  70%|██████████████████████████████████████████▏                 | 130/185 [02:03<00:52,  1.06batch/s]\u001b[A\n",
      "Validation round:  71%|██████████████████████████████████████████▍                 | 131/185 [02:04<00:52,  1.02batch/s]\u001b[A\n",
      "Validation round:  71%|██████████████████████████████████████████▊                 | 132/185 [02:05<00:51,  1.03batch/s]\u001b[A\n",
      "Validation round:  72%|███████████████████████████████████████████▏                | 133/185 [02:06<00:50,  1.03batch/s]\u001b[A\n",
      "Validation round:  72%|███████████████████████████████████████████▍                | 134/185 [02:07<00:49,  1.03batch/s]\u001b[A\n",
      "Validation round:  73%|███████████████████████████████████████████▊                | 135/185 [02:08<00:49,  1.02batch/s]\u001b[A\n",
      "Validation round:  74%|████████████████████████████████████████████                | 136/185 [02:09<00:48,  1.01batch/s]\u001b[A\n",
      "Validation round:  74%|████████████████████████████████████████████▍               | 137/185 [02:10<00:47,  1.01batch/s]\u001b[A\n",
      "Validation round:  75%|████████████████████████████████████████████▊               | 138/185 [02:11<00:45,  1.03batch/s]\u001b[A\n",
      "Validation round:  75%|█████████████████████████████████████████████               | 139/185 [02:12<00:44,  1.04batch/s]\u001b[A\n",
      "Validation round:  76%|█████████████████████████████████████████████▍              | 140/185 [02:13<00:44,  1.02batch/s]\u001b[A\n",
      "Validation round:  76%|█████████████████████████████████████████████▋              | 141/185 [02:14<00:43,  1.01batch/s]\u001b[A\n",
      "Validation round:  77%|██████████████████████████████████████████████              | 142/185 [02:15<00:42,  1.02batch/s]\u001b[A\n",
      "Validation round:  77%|██████████████████████████████████████████████▍             | 143/185 [02:16<00:39,  1.06batch/s]\u001b[A\n",
      "Validation round:  78%|██████████████████████████████████████████████▋             | 144/185 [02:17<00:38,  1.05batch/s]\u001b[A\n",
      "Validation round:  78%|███████████████████████████████████████████████             | 145/185 [02:18<00:38,  1.05batch/s]\u001b[A\n",
      "Validation round:  79%|███████████████████████████████████████████████▎            | 146/185 [02:19<00:38,  1.01batch/s]\u001b[A\n",
      "Validation round:  79%|███████████████████████████████████████████████▋            | 147/185 [02:20<00:37,  1.00batch/s]\u001b[A\n",
      "Validation round:  80%|████████████████████████████████████████████████            | 148/185 [02:21<00:37,  1.00s/batch]\u001b[A\n",
      "Validation round:  81%|████████████████████████████████████████████████▎           | 149/185 [02:22<00:36,  1.01s/batch]\u001b[A\n",
      "Validation round:  81%|████████████████████████████████████████████████▋           | 150/185 [02:23<00:35,  1.00s/batch]\u001b[A\n",
      "Validation round:  82%|████████████████████████████████████████████████▉           | 151/185 [02:24<00:34,  1.01s/batch]\u001b[A\n",
      "Validation round:  82%|█████████████████████████████████████████████████▎          | 152/185 [02:25<00:32,  1.00batch/s]\u001b[A\n",
      "Validation round:  83%|█████████████████████████████████████████████████▌          | 153/185 [02:26<00:33,  1.03s/batch]\u001b[A\n",
      "Validation round:  83%|█████████████████████████████████████████████████▉          | 154/185 [02:27<00:31,  1.02s/batch]\u001b[A\n",
      "Validation round:  84%|██████████████████████████████████████████████████▎         | 155/185 [02:28<00:29,  1.01batch/s]\u001b[A\n",
      "Validation round:  84%|██████████████████████████████████████████████████▌         | 156/185 [02:29<00:27,  1.05batch/s]\u001b[A\n",
      "Validation round:  85%|██████████████████████████████████████████████████▉         | 157/185 [02:30<00:26,  1.06batch/s]\u001b[A\n",
      "Validation round:  85%|███████████████████████████████████████████████████▏        | 158/185 [02:31<00:25,  1.06batch/s]\u001b[A\n",
      "Validation round:  86%|███████████████████████████████████████████████████▌        | 159/185 [02:32<00:24,  1.08batch/s]\u001b[A\n",
      "Validation round:  86%|███████████████████████████████████████████████████▉        | 160/185 [02:33<00:22,  1.10batch/s]\u001b[A\n",
      "Validation round:  87%|████████████████████████████████████████████████████▏       | 161/185 [02:33<00:21,  1.11batch/s]\u001b[A\n",
      "Validation round:  88%|████████████████████████████████████████████████████▌       | 162/185 [02:34<00:20,  1.12batch/s]\u001b[A\n",
      "Validation round:  88%|████████████████████████████████████████████████████▊       | 163/185 [02:35<00:19,  1.10batch/s]\u001b[A\n",
      "Validation round:  89%|█████████████████████████████████████████████████████▏      | 164/185 [02:36<00:19,  1.08batch/s]\u001b[A\n",
      "Validation round:  89%|█████████████████████████████████████████████████████▌      | 165/185 [02:37<00:18,  1.09batch/s]\u001b[A\n",
      "Validation round:  90%|█████████████████████████████████████████████████████▊      | 166/185 [02:38<00:17,  1.09batch/s]\u001b[A\n",
      "Validation round:  90%|██████████████████████████████████████████████████████▏     | 167/185 [02:39<00:16,  1.07batch/s]\u001b[A\n",
      "Validation round:  91%|██████████████████████████████████████████████████████▍     | 168/185 [02:40<00:16,  1.05batch/s]\u001b[A\n",
      "Validation round:  91%|██████████████████████████████████████████████████████▊     | 169/185 [02:41<00:15,  1.07batch/s]\u001b[A\n",
      "Validation round:  92%|███████████████████████████████████████████████████████▏    | 170/185 [02:42<00:13,  1.08batch/s]\u001b[A\n",
      "Validation round:  92%|███████████████████████████████████████████████████████▍    | 171/185 [02:43<00:12,  1.08batch/s]\u001b[A\n",
      "Validation round:  93%|███████████████████████████████████████████████████████▊    | 172/185 [02:44<00:12,  1.08batch/s]\u001b[A\n",
      "Validation round:  94%|████████████████████████████████████████████████████████    | 173/185 [02:45<00:11,  1.08batch/s]\u001b[A\n",
      "Validation round:  94%|████████████████████████████████████████████████████████▍   | 174/185 [02:45<00:09,  1.10batch/s]\u001b[A\n",
      "Validation round:  95%|████████████████████████████████████████████████████████▊   | 175/185 [02:46<00:09,  1.09batch/s]\u001b[A\n",
      "Validation round:  95%|█████████████████████████████████████████████████████████   | 176/185 [02:47<00:08,  1.10batch/s]\u001b[A\n",
      "Validation round:  96%|█████████████████████████████████████████████████████████▍  | 177/185 [02:48<00:07,  1.07batch/s]\u001b[A\n",
      "Validation round:  96%|█████████████████████████████████████████████████████████▋  | 178/185 [02:49<00:06,  1.08batch/s]\u001b[A\n",
      "Validation round:  97%|██████████████████████████████████████████████████████████  | 179/185 [02:50<00:05,  1.10batch/s]\u001b[A\n",
      "Validation round:  97%|██████████████████████████████████████████████████████████▍ | 180/185 [02:51<00:04,  1.08batch/s]\u001b[A\n",
      "Validation round:  98%|██████████████████████████████████████████████████████████▋ | 181/185 [02:52<00:03,  1.08batch/s]\u001b[A\n",
      "Validation round:  98%|███████████████████████████████████████████████████████████ | 182/185 [02:53<00:02,  1.06batch/s]\u001b[A\n",
      "Validation round:  99%|███████████████████████████████████████████████████████████▎| 183/185 [02:54<00:01,  1.05batch/s]\u001b[A\n",
      "Validation round:  99%|███████████████████████████████████████████████████████████▋| 184/185 [02:55<00:00,  1.02batch/s]\u001b[A\n",
      "Validation round: 100%|████████████████████████████████████████████████████████████| 185/185 [02:56<00:00,  1.04batch/s]\u001b[A\n",
      "                                                                                                                        \u001b[AINFO: Validation Dice score: 0.2220274806022644\n",
      "Epoch 1/5:  24%|███████████▍                                   | 407/1669 [28:55<1:29:42,  4.26s/img, loss (batch)=1.13]\n",
      "INFO: Saved interrupt\n",
      "ERROR: Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "INFO: \n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_252/2428837494.py\", line 189, in <module>\n",
      "    amp=args.amp)\n",
      "  File \"/tmp/ipykernel_252/2428837494.py\", line 89, in train_net\n",
      "    masks_pred = net(images)\n",
      "  File \"/home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/tmp/ipykernel_252/3889472007.py\", line 24, in forward\n",
      "    x3 = self.down2(x2)\n",
      "  File \"/home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/tmp/ipykernel_252/1271234201.py\", line 40, in forward\n",
      "    return self.maxpool_conv(x)\n",
      "  File \"/home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 141, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/tmp/ipykernel_252/1271234201.py\", line 25, in forward\n",
      "    return self.double_conv(x)\n",
      "  File \"/home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages/torch/nn/modules/container.py\", line 141, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages/torch/nn/modules/conv.py\", line 446, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"/home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages/torch/nn/modules/conv.py\", line 443, in _conv_forward\n",
      "    self.padding, self.dilation, self.groups)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_252/2428837494.py\", line 193, in <module>\n",
      "    sys.exit(0)\n",
      "  File \"/home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages/wandb/sdk/lib/exit_hooks.py\", line 38, in exit\n",
      "    self._orig_exit(orig_code)\n",
      "  File \"/home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages/wandb/sdk/lib/exit_hooks.py\", line 38, in exit\n",
      "    self._orig_exit(orig_code)\n",
      "  File \"/home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages/wandb/sdk/lib/exit_hooks.py\", line 38, in exit\n",
      "    self._orig_exit(orig_code)\n",
      "  [Previous line repeated 3 more times]\n",
      "SystemExit: 0\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/mlisaius/miniconda3/envs/unetenv/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_252/2428837494.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    188\u001b[0m                   \u001b[0mval_percent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                   amp=args.amp)\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_252/2428837494.py\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(net, device, epochs, batch_size, learning_rate, val_percent, save_checkpoint, img_scale, amp)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0mmasks_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unetenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_252/3889472007.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mx4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unetenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_252/1271234201.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unetenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unetenv/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unetenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_252/1271234201.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unetenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unetenv/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unetenv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unetenv/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unetenv/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_252/2428837494.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saved interrupt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/unetenv/lib/python3.7/site-packages/wandb/sdk/lib/exit_hooks.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_orig_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unetenv/lib/python3.7/site-packages/wandb/sdk/lib/exit_hooks.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_orig_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unetenv/lib/python3.7/site-packages/wandb/sdk/lib/exit_hooks.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_orig_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unetenv/lib/python3.7/site-packages/wandb/sdk/lib/exit_hooks.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_orig_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unetenv/lib/python3.7/site-packages/wandb/sdk/lib/exit_hooks.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_orig_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unetenv/lib/python3.7/site-packages/wandb/sdk/lib/exit_hooks.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_orig_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unetenv/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2069\u001b[0m                            'the full traceback.\\n']\n\u001b[1;32m   2070\u001b[0m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0;32m-> 2071\u001b[0;31m                                                                      value))\n\u001b[0m\u001b[1;32m   2072\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2073\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unetenv/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unetenv/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n\u001b[1;32m    632\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0mchained_exception_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m                 + out_list)\n\u001b[0m\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unetenv/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1368\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unetenv/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1268\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             )\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unetenv/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1125\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unetenv/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/unetenv/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "\"\"\" Implementation of model \"\"\"\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "wandb.init(project=\"my-test-project\", entity=\"mlisaius\")\n",
    "\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "dir_img = Path('/mnt/g/Shared drives/2021-gtc-sea-ice/trainingdata/tiled/')\n",
    "dir_checkpoint = Path('/mnt/g/Shared drives/2021-gtc-sea-ice/model/checkpoints/')\n",
    "\n",
    "\n",
    "def train_net(net,\n",
    "              device,\n",
    "              epochs: int = 5,\n",
    "              batch_size: int = 10,\n",
    "              learning_rate: float = 0.001,\n",
    "              val_percent: float = 0.1,\n",
    "              save_checkpoint: bool = True,\n",
    "              img_scale: float = 0.5,\n",
    "              amp: bool = False):\n",
    "    # 1. Create dataset\n",
    "    img_list = create_npy_list(dir_img)\n",
    "    dataset = CustomImageDataset(img_list, True)\n",
    "    \n",
    "    # 2. Split into train / validation partitions\n",
    "    n_val = int(len(dataset) * val_percent)\n",
    "    n_train = len(dataset) - n_val\n",
    "    train_set, val_set = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(0))\n",
    "    \n",
    "    # 3. Create data loaders\n",
    "    loader_args = dict(batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)\n",
    "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)\n",
    "    \n",
    "    # Initialize logging\n",
    "    experiment = wandb.init(project='U-Net', resume='allow', anonymous='must')\n",
    "    experiment.config.update(dict(epochs=epochs, batch_size=batch_size, learning_rate=learning_rate,\n",
    "                                  val_percent=val_percent, save_checkpoint=save_checkpoint, img_scale=img_scale,\n",
    "                                  amp=amp))\n",
    "\n",
    "    logging.info(f'''Starting training:\n",
    "        Epochs:          {epochs}\n",
    "        Batch size:      {batch_size}\n",
    "        Learning rate:   {learning_rate}\n",
    "        Training size:   {n_train}\n",
    "        Validation size: {n_val}\n",
    "        Checkpoints:     {save_checkpoint}\n",
    "        Device:          {device.type}\n",
    "        Images scaling:  {img_scale}\n",
    "        Mixed Precision: {amp}\n",
    "    ''')\n",
    "\n",
    "    # 4. Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=learning_rate, weight_decay=1e-8, momentum=0.9)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)  # goal: maximize Dice score\n",
    "    grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    global_step = 0\n",
    "    \n",
    "    # 5. Begin training\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        epoch_loss = 0\n",
    "        with tqdm(total=n_train, desc=f'Epoch {epoch + 1}/{epochs}', unit='img') as pbar:\n",
    "            for batch in train_loader:\n",
    "                images = batch['image']\n",
    "                true_masks = batch['mask']\n",
    "                \n",
    "                assert images.shape[1] == net.n_channels, \\\n",
    "                    f'Network has been defined with {net.n_channels} input channels, ' \\\n",
    "                    f'but loaded images have {images.shape[1]} channels of {images.shape}. Please check that ' \\\n",
    "                    'the images are loaded correctly.'\n",
    "\n",
    "                images = images.to(device=device, dtype=torch.float32)\n",
    "                true_masks = true_masks.to(device=device, dtype=torch.long)\n",
    "\n",
    "                with torch.cuda.amp.autocast(enabled=amp):\n",
    "                    masks_pred = net(images)\n",
    "                    loss = criterion(masks_pred, true_masks) \\\n",
    "                           + dice_loss(F.softmax(masks_pred, dim=1).float(),\n",
    "                                       F.one_hot(true_masks, net.n_classes).permute(0, 3, 1, 2).float(),\n",
    "                                       multiclass=True)\n",
    "                # change number for permute?\n",
    "                \n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                grad_scaler.scale(loss).backward()\n",
    "                grad_scaler.step(optimizer)\n",
    "                grad_scaler.update()\n",
    "\n",
    "                pbar.update(images.shape[0])\n",
    "                global_step += 1\n",
    "                epoch_loss += loss.item()\n",
    "                experiment.log({\n",
    "                    'train loss': loss.item(),\n",
    "                    'step': global_step,\n",
    "                    'epoch': epoch\n",
    "                })\n",
    "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "\n",
    "                # Evaluation round\n",
    "                division_step = (n_train // (10 * batch_size))\n",
    "                if division_step > 0:\n",
    "                    if global_step % division_step == 0:\n",
    "                        histograms = {}\n",
    "                        for tag, value in net.named_parameters():\n",
    "                            tag = tag.replace('/', '.')\n",
    "                            histograms['Weights/' + tag] = wandb.Histogram(value.data.cpu())\n",
    "                            histograms['Gradients/' + tag] = wandb.Histogram(value.grad.data.cpu())\n",
    "\n",
    "                        val_score = evaluate(net, val_loader, device)\n",
    "                        scheduler.step(val_score)\n",
    "\n",
    "                        logging.info('Validation Dice score: {}'.format(val_score))\n",
    "                        experiment.log({\n",
    "                            'learning rate': optimizer.param_groups[0]['lr'],\n",
    "                            'validation Dice': val_score,\n",
    "                            'images': wandb.Image(images[0].cpu()),\n",
    "                            'masks': {\n",
    "                                'true': wandb.Image(true_masks[0].float().cpu()),\n",
    "                                'pred': wandb.Image(torch.softmax(masks_pred, dim=1).argmax(dim=1)[0].float().cpu()),\n",
    "                            },\n",
    "                            'step': global_step,\n",
    "                            'epoch': epoch,\n",
    "                            **histograms\n",
    "                        })\n",
    "\n",
    "        if save_checkpoint:\n",
    "            Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
    "            torch.save(net.state_dict(), str(dir_checkpoint / 'checkpoint_epoch{}.pth'.format(epoch + 1)))\n",
    "            logging.info(f'Checkpoint {epoch + 1} saved!')\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Train the UNet on images and target masks')\n",
    "    parser.add_argument('--epochs', '-e', metavar='E', type=int, default=5, help='Number of epochs')\n",
    "    parser.add_argument('--batch-size', '-b', dest='batch_size', metavar='B', type=int, default=1, help='Batch size')\n",
    "    parser.add_argument('--learning-rate', '-l', metavar='LR', type=float, default=0.00001,\n",
    "                        help='Learning rate', dest='lr')\n",
    "    parser.add_argument('--load', '-f', type=str, default=False, help='Load model from a .pth file')\n",
    "    parser.add_argument('--scale', '-s', type=float, default=0.5, help='Downscaling factor of the images')\n",
    "    parser.add_argument('--validation', '-v', dest='val', type=float, default=10.0,\n",
    "                        help='Percent of the data that is used as validation (0-100)')\n",
    "    parser.add_argument('--amp', action='store_true', default=False, help='Use mixed precision')\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = get_args()\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logging.info(f'Using device {device}')\n",
    "\n",
    "    # Change here to adapt to your data\n",
    "    # n_channels=3 for RGB images\n",
    "    # n_classes is the number of probabilities you want to get per pixel\n",
    "    net = UNet(n_channels=1, n_classes=2, bilinear=True)\n",
    "\n",
    "    logging.info(f'Network:\\n'\n",
    "                 f'\\t{net.n_channels} input channels\\n'\n",
    "                 f'\\t{net.n_classes} output channels (classes)\\n'\n",
    "                 f'\\t{\"Bilinear\" if net.bilinear else \"Transposed conv\"} upscaling')\n",
    "\n",
    "#    if args.load:\n",
    "#        net.load_state_dict(torch.load(args.load, map_location=device))\n",
    "#        logging.info(f'Model loaded from {args.load}')\n",
    "\n",
    "    net.to(device=device)\n",
    "    try:\n",
    "        train_net(net=net,\n",
    "                  epochs=args.epochs,\n",
    "                  batch_size=args.batch_size,\n",
    "                  learning_rate=args.lr,\n",
    "                  device=device,\n",
    "                  img_scale=args.scale,\n",
    "                  val_percent=args.val / 100,\n",
    "                  amp=args.amp)\n",
    "    except KeyboardInterrupt:\n",
    "        torch.save(net.state_dict(), 'INTERRUPTED.pth')\n",
    "        logging.info('Saved interrupt')\n",
    "        sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d1dcb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
